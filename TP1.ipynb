{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a66888c7-bcc1-4c6c-a549-70985c194551",
   "metadata": {},
   "source": [
    "# TP n°1 : Exploration de pré-traitement de données\n",
    "\n",
    "Dans ce TP, nous allons voir :\n",
    "- comment inspecter et visualiser le contenu d'un jeu de données avec les bibliothèques `pandas` et `seaborn`,\n",
    "- comment entraîner un modèle scikit-learn et mesurer sa performance en séparant données d'entraînement et données de test,\n",
    "- comment pré-traîter les données numériques et catégoriques pour augmenter la performance d'un modèle.\n",
    "\n",
    "Votre travail est de compléter les cellules de code qui contiennent un commentaire \"# A compléter ici\".\n",
    "Commencez par remplir la case ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b149a6-f453-4584-85b3-a5dc252c4f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A compléter ici :\n",
    "# NOM :\n",
    "# Prénom :\n",
    "# N° étudiant :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0de58a5-08ba-46b2-803e-e33035327193",
   "metadata": {},
   "source": [
    "## Documentation :\n",
    "\n",
    "**Pendant le TP, n'hésitez pas à aller consulter la [documentation de scikit-learn](https://scikit-learn.org/stable/api/index.html), accessible à ce lien : [https://scikit-learn.org/stable/api/index.html](https://scikit-learn.org/stable/api/index.html)**. Elle contient de nombreuses explications sur comment utiliser les fonctions introduites dans ce TP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de4f916-eeb5-4aeb-a506-d6d918fcba82",
   "metadata": {},
   "source": [
    "## 0. Préparation du TP\n",
    "\n",
    "Le code ci-dessous installe puis importe les librairies python nécessaire pour le TP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634e8290-b0bd-401e-b918-e67222a43924",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy matplotlib pandas scikit-learn seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63fb5ea-7f06-459a-b20e-29b4c5c8c475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95702d43-1e5e-4d4e-bec6-d527b2d72a74",
   "metadata": {},
   "source": [
    "## 1. Exploration et visualisation de données\n",
    "\n",
    "On commence par charger les données du dataset \"[palmer penguins](https://allisonhorst.github.io/palmerpenguins/)\". L'objet qu'on obtient est une [DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) pandas, un type spécialisé pour la gestion de jeux de données.\n",
    "\n",
    "La fonction `.info()` d'une DataFrame permet d'afficher des informations sur le jeu de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77194e2-b56c-454e-a023-6e44bc756491",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_penguins = sns.load_dataset(\"penguins\")\n",
    "data_penguins.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b27129e-51ac-45ba-928a-927e4c652375",
   "metadata": {},
   "source": [
    "La fonction `.head()` d'une DataFrame permet d'afficher le nom de ses colonnes ainsi que le contenu de ses 5 premières lignes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9017b06-081d-4ffc-84ef-3ebe9410f43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_penguins.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c1bdcf-0363-46a2-983e-a6c46f6421e2",
   "metadata": {},
   "source": [
    "Pour accéder à une colonne spécifique de la dataframe, on écrit `dataframe[\"nom_colonne\"]`.\n",
    "Ensuite, la fonction `value_counts()` renvoie des informations sur les valeurs dans la colonne : les différentes valeurs et leur fréquence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635b6f8f-e2c0-4c9c-8ebe-5ff74bebd6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "species = data_penguins[\"species\"]\n",
    "species.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2aa3d7-f8d1-4106-bcd7-cd55e6d5c81f",
   "metadata": {},
   "source": [
    "On peut observer ici que le jeu de données contient 68 pingouins de l'espèce \"Chinstrap\".\n",
    "\n",
    "Pour obtenir des informations sur les données numériques, on peut utiliser la fonction `.describe()`, comme suit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00b62e1-4cb6-42c3-9e15-0ba7a8c6254e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_penguins.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c1341b-915d-499b-ac85-82307aa2b03a",
   "metadata": {},
   "source": [
    "**Q° 1**: écrire du code permettant de savoir combien de pingouins femelle le jeu de données contient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da86b39-6d63-46af-b219-9d0ab4152f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A compléter ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6aa82b5-d60d-46ab-8aa8-e3dd124e45e1",
   "metadata": {},
   "source": [
    "La fonction `.hist()` permet d'afficher un histogramme pour visualiser la répartition des données numériques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670a55a2-1118-4951-b8b7-d2568929fd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = data_penguins.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cc1f22-9efa-417d-b162-2cef628d66c7",
   "metadata": {},
   "source": [
    "La fonction `seaborn.pairplot()` permet d'afficher des graphiques montrant la répartition d'une colonne en fonction d'une autre. Le paramètre `hue` permet de choisir une colonne selon laquelle colorier les points. Ici, on choisit la colonne qu'on essaiera plus tard de prédire, l'espèce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f79215-087f-4a88-9a35-d322fea8f36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.pairplot(data_penguins, hue=\"species\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476ddbc8-7b47-4691-96f3-80ae51a53360",
   "metadata": {},
   "source": [
    "### Exercice : à vous !\n",
    "\n",
    "1. Chargez le dataset \"iris\" avec la fonction `load_dataset()` de `seaborn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55a5f6f-022c-40b9-b26d-6df6ee440586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A compléter ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d28c5b6-6206-452d-93e2-8129f26f5a1b",
   "metadata": {},
   "source": [
    "2. Combien de colonnes catégoriques ? Combien sont numériques ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27acb45a-456c-4e3d-8270-d9d2b93f66f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A compléter ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61d1aab-fd5e-401b-8a4a-0a32f85842c1",
   "metadata": {},
   "source": [
    "3. Affichez un histogramme de chaque feature (colonne) numérique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e64d759-ac10-4510-9d3e-c3eb2d814d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A compléter ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13cee8a-0cb5-49c3-97c2-79f579a03428",
   "metadata": {},
   "source": [
    "4. Affichez la distribution de chaque paire de features, en fonction de l'espèce d'iris (colonne \"species\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7887c1-bb50-4530-ae1b-5f77f2094493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A compléter ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e8f446-f3d1-48b9-bf0c-ea96e982a28d",
   "metadata": {},
   "source": [
    "5. Au vu de ces graphes, pensez vous qu'il soit facile de déterminer l'espèce d'une iris à partir des colonnes `petal_width` et  `petal_length` ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1881fb-aa4f-4af5-9858-9742d5bc31ac",
   "metadata": {},
   "source": [
    "> Répondre ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c23a199-3300-4203-9f79-ea3eac80a0ad",
   "metadata": {},
   "source": [
    "# 2. Entraîner un modèle sur des données numériques\n",
    "\n",
    "On va dans un premier temps se restreindre aux données numériques dans le jeu de données \"palmer penguins\", en ignorant les lignes qui contiennent des valeurs manquantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ce6fc4-cdd0-4e7b-805c-ba13fa27d3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_penguins_no_na = data_penguins.dropna()\n",
    "numerical_columns = [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\"]\n",
    "data = data_penguins_no_na[numerical_columns]\n",
    "target = data_penguins_no_na[\"species\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af05ba1e-2e4f-43c1-8769-312e326ef682",
   "metadata": {},
   "source": [
    "La première étape est de séparer les données deux, une partie pour l'entraînement et une partie pour la validation.  \n",
    "Ici, test size indique la proportion des données à mettre dans la partie de validation; ici, 0.3 signifie 30%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46ff81d-a55a-4503-9574-67e8827a4476",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size = 0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea275ea-b633-4910-a185-aff650ea9bad",
   "metadata": {},
   "source": [
    "On entraîne un modèle linéaire simple, la régression logistique (que l'on discutera plus en détail dans un cours à venir), sur les données d'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731ed0dc-a2f6-47af-a47c-8eefa667e9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from time import time\n",
    "\n",
    "model = LogisticRegression()\n",
    "start = time()\n",
    "_ = model.fit(X_train, y_train)\n",
    "elapsed = time() - start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8982155f-3af9-465f-b758-4a60267c15b3",
   "metadata": {},
   "source": [
    "On calcule maintenant sa précision sur le jeu de données de test. Vous devriez observer un score d'environ 97% en environ 0.2 sec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fad23d7-9b0f-487e-9f38-3ba1a0991a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.score(X_test, y_test)\n",
    "print(f\"Score sur les données de test: {score*100:.3f}%, entraîné en {elapsed:.3f}s.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b004a5ae-6198-41db-947b-12dced19b62b",
   "metadata": {},
   "source": [
    "## Amélioration des performances : scaling des données.\n",
    "\n",
    "Les modèles linéaires sont sensibles à l'ordre de grandeur des données reçus en entrée, et fonctionnent mieux lorsque les données sont centrées et réduites.\n",
    "Ce n'est pas le cas de nos données, c'est pourquoi le modèle linéaire emet un `ConvergenceWarning` lors de l'appel à `fit()`.\n",
    "\n",
    "Pour essayer d'améliorer les performances du modèle, on va centrer et réduire les données à l'aide d'un `StandardScaler` avant de les passer au modèle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d2f086-dd6b-4316-bd0b-110f648f8098",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "scaler = StandardScaler()\n",
    "classifier = LogisticRegression()\n",
    "scaled_model = make_pipeline(scaler, classifier)\n",
    "\n",
    "start = time()\n",
    "scaled_model.fit(X_train, y_train)\n",
    "elapsed = time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a875dde2-ee45-4735-aed4-1ed951e23c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = scaled_model.score(X_test, y_test)\n",
    "print(f\"Score sur les données de test: {score*100:.3f}%, entraîné en {elapsed:.3f}s.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff1ba47-4c99-460c-96b7-866ab61f7333",
   "metadata": {},
   "source": [
    "On observe qu'après avoir scalé les données, la précision du modèle est restée la même, mais le temps d'entraînement a diminué !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ae94a4-aaa3-4517-b7ef-e8550b5955a0",
   "metadata": {},
   "source": [
    "## Exercice : à vous !\n",
    "\n",
    "Dans cet exerice, on utilisera un jeu de données contenant des informations sur des quarties en Californie, à partir desquelles il faut prédire le prix vente median d'une maison dans le quartier (\"MedHouseVal\"). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4122c0a9-b697-454b-9f31-5b4542888fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "california_housing = fetch_california_housing(as_frame=True).frame\n",
    "target = california_housing[\"MedHouseVal\"]\n",
    "data = california_housing.drop(columns = [\"MedHouseVal\"])\n",
    "\n",
    "california_housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6a03bb-1e56-4c66-a046-bd68c053a586",
   "metadata": {},
   "source": [
    "1. La colonne cible (\"MedHouseVal\") est-elle numérique ou catégorique ? En conséquence, s'agit-il d'un problème de régression ou de classification ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1f0bbf-d208-441b-8bd0-42c5b0b92744",
   "metadata": {},
   "source": [
    "> Répondre ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43386251-9bc3-4f28-99bb-40baa8e295c5",
   "metadata": {},
   "source": [
    "2. Séparer les données en un ensemble d'entraînement contenant 80% des données et un ensemble de test contenant 20% des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547eaff6-0015-4722-a1e8-3b0f832dc0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A compléter ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c100e6d-2313-4e1e-8a70-d2992863cd14",
   "metadata": {},
   "source": [
    "3. Entraîner un modèle linéaire adapté au type de problème (`LinearRegression` pour la régression, `LogisticRegression` pour la classification), en mesurant le temps d'entraînement.\n",
    "Quelle est la précision du modèle sur les données de test ? Et sur les données d'entraînement ? Est-ce normal ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eeb671-3d8e-407a-9b9d-eb9322b2cdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A compléter ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5682ecf0-3db9-4013-8804-10382b4f1c88",
   "metadata": {},
   "source": [
    "# 3. Travailler avec les données catégoriques\n",
    "\n",
    "Dans cette dernière partie du TP, nous allons entraîner un modèle de classification sur le jeu de données \"Adult census\", que l'on a vu en cours Mardi.\n",
    "Le but sera d'utiliser à la fois les données numériques et les données catégoriques dans le modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc77f38-2210-400d-a1ff-3997ce56c3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -L -o adult-census-income.zip https://www.kaggle.com/api/v1/datasets/download/uciml/adult-census-income\n",
    "!unzip -o adult-census-income.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436096d1-9c4a-4d1e-b7a4-32f08c33a50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data (as pandas dataframes) \n",
    "data = pd.read_csv(\"adult.csv\").dropna()\n",
    "X = data[[\"age\", \"workclass\", \"fnlwgt\", \"education\", \"marital.status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"capital.gain\", \"capital.loss\", \"hours.per.week\", \"native.country\"]]\n",
    "y = data[\"income\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9239baf7-77da-4316-9196-9e628adc8f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baca0e0c-73f4-4ca2-b68c-2b54251360b0",
   "metadata": {},
   "source": [
    "Plutôt que d'entrer à la main le nom des colonnes numériques et catégoriques, on va utiliser la fonction `make_column_selector` de `scikit-learn` pour les détecter automatiquement.\n",
    "Les paramètres `dtype_exclude` et `dtype_include` indique quel type de colonne on veut enlever où garder. Ici, les colonnes catégoriques sont encodées par des `string`, on peut donc les isoler en passant le paramètre `object`. Les colonnes numériques seront généralement du type `float64` ou `int32`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f16051-815e-45e5-95e7-2ebd5ffdaeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_selector as selector\n",
    "\n",
    "numerical_columns_selector = selector(dtype_exclude=object)\n",
    "categorical_columns_selector = selector(dtype_include=object)\n",
    "\n",
    "numerical_columns = numerical_columns_selector(X)\n",
    "categorical_columns = categorical_columns_selector(X)\n",
    "numerical_columns, categorical_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f33b16d-587f-40da-86d1-d080e2b04272",
   "metadata": {},
   "source": [
    "On crée ensuite les objets qui transformeront chaque ensemble de colonne. Ici, on encodera les données catégoriques avec un `OrdinalEncoder`, qui assigne un entier différent à chaque classe. Les données numériques seront centrées et réduites avec un `StandardScaler`, qui met leur moyenne à 0 et leur écart-type à 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1f3c89-bae5-486e-973c-55ffd129a86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "\n",
    "categorical_preprocessor = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
    "numerical_preprocessor = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d397f7e0-28bb-4557-8187-e6d1bfa6cc31",
   "metadata": {},
   "source": [
    "Ensuite, on associe chaque objet à son ensemble de colonnes dans un `ColumnTransformer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9c9d66-cc8b-43ce-8183-fbaaadbfd9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"one-hot-encoder\", categorical_preprocessor, categorical_columns),\n",
    "        (\"standard_scaler\", numerical_preprocessor, numerical_columns),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158b24ac-86d7-475b-a4a3-d85a711f3b6a",
   "metadata": {},
   "source": [
    "On peut alors créer un modèle linéaire de classification, en utilisant `LogisticRegression`, et on le combine avec notre pré-processeur en utilisant `make_pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a056ac-7783-4348-acb2-62eac96f5d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "model = make_pipeline(preprocessor, LogisticRegression(max_iter=500))\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe143dda-b029-4af7-8366-faf9ba0641c5",
   "metadata": {},
   "source": [
    "Enfin, on peut entraîner notre modèle et mesurer sa performance.\n",
    "\n",
    "Dans les sections précédentes, on avait utilisé la fonction `train_test_split` pour séparer les données en un jeu d'entraînement et un jeu de test. Une limitation de cette méthode est qu'elle ne permet de faire qu'une seule mesure empirique de la précision, et ne donne pas d'information sur sa variabilité : il est possible que le modèle soit performant \"par chance\".\n",
    "\n",
    "On va utiliser ici la cross validation, qui entraîne automatiquement le modèle sur plusieurs séparations en deux du jeu de données, et renvoie le score pour chaque itération. Cela permet de mesurer la sensibilité de la performance au choix du jeu de données d'entraînement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d865e99-0286-46cc-94e7-032e60493033",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=5, scoring=\"balanced_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b241287-f66a-4474-b14f-615acc370dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Score: {100*np.mean(scores):.3f}% +/- {100*np.std(scores):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1aaa05-e627-4016-bef4-4aa6f94647b4",
   "metadata": {},
   "source": [
    "Ici, le paramètre `scoring=\"balanced_accuracy\"` signifie que l'on veut compenser le déséquilibre des valeurs dans `y`. En effet, la valeur \"<=50K\" apparaît 24 720 fois, alors que la valeur \"<50k\" apparaît seulement 7841 fois! Un modèle qui répondrait tout le temps \"<=50K\" aurait donc une précision de plus de 75% !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d375903-7ad2-43b3-bf5f-6831ca788a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3b6f5f-d195-414b-aeba-05f4237ed8ff",
   "metadata": {},
   "source": [
    "## Exercice : à vous !\n",
    "\n",
    "Dans la section précédente, on a utilisé un `OrdinalEncoder` pour encoder les variables catégoriques. Les modèles linéaires ont du mal àutiliser les données encodées en ordinaux.\n",
    "Dans cet exercice, on va entrainer le même modèle, mais en encodant les colonnes catégoriques avec un `OneHotEncoder`, et regarder si on observe une différence de performance ou non."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da499b06-44fe-4605-a7aa-dc2e6100004a",
   "metadata": {},
   "source": [
    "1. Créez un `OneHotEncoder` pour encoder les colonnes catégoriques et un `StandardScaler` pour encoder les variables numériques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09096957-9b0c-4ff2-ba72-3ab8c5a38af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A compléter ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c155a0-4647-45ba-8e0e-e5a2f0da465c",
   "metadata": {},
   "source": [
    "2. Créez un `ColumnTransformer` qui prend en charge la transformation de toutes les colonnes, en utilisant les objets de la question précédente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d19cad-2425-44d3-a74d-5d3e84d9dc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A compléter ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1599cc1a-e7bb-4a22-9e5d-3674decf434d",
   "metadata": {},
   "source": [
    "3. Créez un modèle de classification basé sur une `LogisticRegression` avec paramètre `max_iter=500`, et le préprocesseur de la question précédente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7f1f68-238f-4500-847e-8b3a2efce3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A compléter ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9697a1b8-3544-48d0-bce2-02db8e86e0c3",
   "metadata": {},
   "source": [
    "4. Utilisez `cross_val_score` avec `cv=5` et `scoring=\"balanced_accuracy\"` pour mesurer les performances du nouveau modèle. Sont-elles meilleures que pour celui où les données catégoriques sont encodées avec un `OrdinalEncoder` ?\n",
    "Cela correspond-t-il à ce que l'on attendait ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97725b3-0330-4c10-b088-3394fe02e9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A compléter ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0f12ba-a82e-44c6-9712-dc849f42b252",
   "metadata": {},
   "source": [
    "## Exercice : à vous !\n",
    "\n",
    "On a jusqu'ici considéré les modèles linéaires (`LinearRegression` et `LogisticRegression`). Dans cet exercice, on s'intéressera à un modèle plus complexe, `sklearn.ensemble.HistGradientBoostingClassifier`.\n",
    "\n",
    "Le but est de répondre aux questions suivantes :\n",
    "- Le scaling des colonnes améliore-t-il les performances d'un `HistGradientBoostingClassifier` ?\n",
    "- Quel est le meilleure encodage de featues catégoriques pour ce modèle : one-hot ou ordinal ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703a36b7-9767-40e3-8884-a5a59c8f0db2",
   "metadata": {},
   "source": [
    "1. Créez un modèle qui encode les colonnes catégoriques en **ordinaux** et ne change pas les colonnes numériques (vous pouvez utiliser l'argument `remainder=\"passthrough\"` de `ColumnTransformer`). Mesurez sa performance à l'aide de la cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3f528d-84fc-40eb-913b-ea533047ab02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A compléter ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad32068-dd00-4118-8060-51c0085aef51",
   "metadata": {},
   "source": [
    "2. Créez un modèle qui encode les colonnes catégoriques en ordinaux et **applique du scaling** aux colonnes numériques. Mesurez sa performance à l'aide de la cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e711467-5814-49ec-a615-267bddc9d45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A compléter ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999b1eae-38eb-44b2-82ac-f03f7fc7d89f",
   "metadata": {},
   "source": [
    "3. Que pouvez-vous en conclure sur l'influence du scaling sur les performances du `HistGradientBoostingClassifier` ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84cc3b1-f6a9-46eb-8e01-06d77baf6b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A compléter ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a95cf3-c5df-46e8-a01f-392ddfb6b60d",
   "metadata": {},
   "source": [
    "4. Créez maintenant un modèle qui encode les colonnes catégoriques en **one-hot**, et **applique du scaling** aux colonnes numériques. Mesurez sa performance à l'aide de la cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7b8068-5f47-415b-bf6f-1f5459578e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A compléter ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dbebab-975f-4ed7-9f4e-9926aa1614b8",
   "metadata": {},
   "source": [
    "5. Que pouvez-vous en conclure ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e45d343-3536-4d7e-8536-8f4535da5320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A compléter ici"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
